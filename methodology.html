<section id="methodology" style="font-family: 'Inter', sans-serif; line-height: 1.7; color: #222; max-width: 1100px; margin: auto; padding: 2rem;">
  <h2 style="font-size: 2rem; font-weight: 700; margin-bottom: 1rem;">üß≠ Methodology</h2>

  <h3 style="font-size: 1.5rem; margin-top: 1.5rem;">Overview</h3>
  <p>
    The <strong>Secure Agricultural UAS Control Framework (SAUCF)</strong> is a 
    <strong>voice-driven, secure, and human-in-the-loop drone system</strong> designed 
    for agricultural operations. It enables operators to control UAS missions through 
    natural language commands while maintaining safety, authentication, and reliability.
  </p>
  <ul>
    <li>üßë‚Äçüåæ Reduce complexity for non-expert operators</li>
    <li>üîê Ensure secure access and mission auditability</li>
    <li>üß† Preserve human authority and oversight</li>
  </ul>

  <hr style="margin: 2rem 0;">

  <h3>üèóÔ∏è System Architecture</h3>
  <figure style="text-align: center; margin: 1rem 0;">
    <img src="images/architecture.png" alt="SAUCF System Architecture" style="max-width: 90%; border-radius: 12px; box-shadow: 0 0 10px rgba(0,0,0,0.1);">
    <figcaption style="font-size: 0.9rem; color: #555;">Figure 1. Secure Agricultural UAS Control Framework (SAUCF) Architecture</figcaption>
  </figure>
  <p>
    The system consists of six integrated components forming a secure pipeline:
  </p>
  <ol>
    <li>Multi-modal biometric authentication</li>
    <li>Voice command processing (ASR)</li>
    <li>Natural language intent parsing (LLM)</li>
    <li>Automated mission planning</li>
    <li>Mission visualization and approval</li>
    <li>Supervised onboard execution with telemetry monitoring</li>
  </ol>

  <hr style="margin: 2rem 0;">

  <h3>üîê Security & Authentication</h3>
  <h4>Multi-Modal Biometric Verification</h4>
  <p>
    SAUCF employs a <strong>dual-factor biometric system</strong> combining 
    <strong>voice and face authentication</strong> using modules from 
    <em>Kaizen Voiz</em>. These modules are embedded into the interface, enabling
    secure operator verification and safe access control.
  </p>

  <hr style="margin: 2rem 0;">

  <h3>üó£Ô∏è Natural Language Processing Pipeline</h3>
  <h4>1. Voice Command Acquisition</h4>
  <p>
    Operators issue voice instructions (e.g., ‚ÄúPerform a mapping mission over the north field‚Äù),
    which are processed by <strong>Whisper ASR</strong> running on a GPU-enabled 
    <em>Jetson Nano</em>. This ensures low-latency, high-accuracy transcription of audio into text.
  </p>

  <h4>2. Intent Parsing with LLM (GPT-4)</h4>
  <p>
    The system uses <strong>GPT-4 with function calling</strong> to interpret commands 
    into structured mission parameters. Few-shot prompting maintains agricultural context, 
    while built-in safety checks prevent unsafe operations.
  </p>
  <p>
    For instance, when a user specifies a large field (&gt;4 ha or &gt;6 ha), 
    the system issues warnings about flight time or battery capacity and asks for 
    explicit operator confirmation before continuing.
  </p>

  <hr style="margin: 2rem 0;">

  <h3>üßÆ Automated Mission Planning</h3>
  <h4>1. Flight Pattern Optimization</h4>
  <p>
    Using the open-source <code>uas-flightplan</code> Python library, the planner 
    automatically generates efficient waypoint grids (lawnmower or spiral patterns),
    optimizing for altitude, overlap, and energy efficiency.
  </p>

  <h4>2. Mission Serialization & Visualization</h4>
  <p>
    The system outputs flight plans as <code>.kml</code> files and generates
    interactive <code>.html</code> visualizations overlayed on satellite imagery.
    This allows users to verify and adjust coverage patterns before deployment.
  </p>

  <hr style="margin: 2rem 0;">

  <h3>üöÅ Onboard Execution & Safety Monitoring</h3>
  <figure style="text-align: center; margin: 1rem 0;">
    <img src="images/jetson-integration.png" alt="Jetson Nano Integrated with DJI M300 RTK" style="max-width: 90%; border-radius: 12px; box-shadow: 0 0 10px rgba(0,0,0,0.1);">
    <figcaption style="font-size: 0.9rem; color: #555;">Figure 2. Jetson Nano integrated with DJI M300 RTK</figcaption>
  </figure>
  <p>
    The <strong>NVIDIA Jetson Nano</strong> companion computer executes missions via 
    <strong>DJI‚Äôs Onboard SDK (OSDK)</strong>. It communicates with the flight controller
    using an FT232 serial adapter through the DJI E-Port interface for real-time control.
  </p>

  <h4>Decision Tree-Based Safeguards</h4>
  <figure style="text-align: center; margin: 1rem 0;">
    <img src="images/decision-tree.png" alt="Decision Tree for Mission Execution" style="max-width: 90%; border-radius: 12px; box-shadow: 0 0 10px rgba(0,0,0,0.1);">
    <figcaption style="font-size: 0.9rem; color: #555;">Figure 3. Decision Tree for Mission Execution with Integrated Safeguards</figcaption>
  </figure>
  <ul>
    <li>Pre-flight checks for battery, GPS fix, and payload status</li>
    <li>Continuous telemetry validation and safety guard enforcement</li>
    <li>Automatic abort below 30% battery threshold</li>
    <li>Reactive contingency handling and Return-to-Home sequences</li>
  </ul>

  <h4>Human-in-the-Loop Safety</h4>
  <p>
    The framework ensures manual confirmation before arming or takeoff, with 
    continuous telemetry (GPS, altitude, battery, mode) streamed to ground control 
    via Wi-Fi. RC-based override is always active for immediate intervention, 
    and all events are logged for compliance.
  </p>

  <hr style="margin: 2rem 0;">

  <h3>‚öôÔ∏è Implementation Stack</h3>
  <h4>Hardware Setup</h4>
  <ul>
    <li><strong>Jetson Nano</strong> (GPU-enabled companion computer)</li>
    <li><strong>DJI Matrice 300 RTK</strong> with DJI OSDK</li>
    <li><strong>USB Microphone</strong> for audio capture</li>
    <li><strong>Camera</strong> for face authentication</li>
    <li><strong>FT232 Serial Adapter</strong> via DJI E-Port</li>
  </ul>

  <h4>Software Stack</h4>
  <ul>
    <li>OS: Ubuntu Linux on Jetson</li>
    <li>ASR: Whisper (GPU-accelerated Python)</li>
    <li>Intent Parsing: GPT-4 API via JSON/HTTP</li>
    <li>Mission Planning: Python <code>uas-flightplan</code> library</li>
    <li>Flight Control: Custom C++ apps built on DJI OSDK</li>
    <li>Integration: Lightweight file & serial message protocols</li>
  </ul>

  <h4>Communication Protocols</h4>
  <figure style="text-align: center; margin: 1rem 0;">
    <img src="images/integration-architecture.png" alt="System Integration and Communication Protocols" style="max-width: 90%; border-radius: 12px; box-shadow: 0 0 10px rgba(0,0,0,0.1);">
    <figcaption style="font-size: 0.9rem; color: #555;">Figure 4. System Integration and Communication Protocols</figcaption>
  </figure>
  <ul>
    <li>LLM API: JSON over HTTP</li>
    <li>ASR Output: Plain-text messages</li>
    <li>Mission Planning: File-based KML/JSON exchange</li>
    <li>Flight Control: Serial SDK APIs for deterministic telemetry</li>
  </ul>

  <hr style="margin: 2rem 0;">

  <h3>üß© Validation & Testing</h3>
  <h4>Simulation-to-Reality Transfer</h4>
  <p>
    Initial missions are tested in the <strong>DJI Assistant 2 (Enterprise Edition)</strong> simulator. 
    After validation, they are executed on physical fields to ensure accurate simulation-to-field alignment.
  </p>

  <h4>Performance Metrics</h4>
  <ul>
    <li><strong>Mission Planning Efficiency:</strong> Time from voice input to deployable mission</li>
    <li><strong>Decision Tree Compliance:</strong> Conformance of executed behavior to safety logic</li>
    <li><strong>Command Interpretation Accuracy:</strong> Frequency of manual corrections</li>
    <li><strong>Authentication Reliability:</strong> FAR and FRR across modalities</li>
    <li><strong>Execution Consistency:</strong> GPS trajectory comparison (simulation vs. field)</li>
  </ul>

  <hr style="margin: 2rem 0;">

  <h3>üåæ Summary</h3>
  <p>
    The SAUCF establishes a <strong>secure, modular, and extensible framework</strong> for intelligent, 
    human-supervised drone operations in agriculture. It combines biometric authentication, 
    LLM-driven language understanding, and autonomous mission planning to achieve:
  </p>
  <ul>
    <li>üöÄ Simplified mission control for non-technical users</li>
    <li>‚úÖ High reliability and safety compliance</li>
    <li>üì° Real-time human oversight with full auditability</li>
  </ul>
</section>
